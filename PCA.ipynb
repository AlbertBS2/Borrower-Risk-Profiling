{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91f197c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan data loaded successfully.\n",
      "Unemployment rate data loaded and merged successfully.\n",
      "Loan and unemployment data merged successfully.\n",
      "Data preprocessing completed successfully.\n",
      "Initial data shape: (2260668, 98)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m data = preprocess_data(loan_data, unemployment_rate_data)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInitial data shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Drop non-numeric columns and the target column `default` from features (but keep for reference)\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data.columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\anaconda3\\envs\\riskBorrow\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\anaconda3\\envs\\riskBorrow\\Lib\\site-packages\\pandas\\core\\frame.py:1398\u001b[39m, in \u001b[36mDataFrame.to_string\u001b[39m\u001b[34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, max_cols, show_dimensions, decimal, line_width, min_rows, max_colwidth, encoding)\u001b[39m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mdisplay.max_colwidth\u001b[39m\u001b[33m\"\u001b[39m, max_colwidth):\n\u001b[32m   1380\u001b[39m     formatter = fmt.DataFrameFormatter(\n\u001b[32m   1381\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1382\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1396\u001b[39m         decimal=decimal,\n\u001b[32m   1397\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mline_width\u001b[49m\u001b[43m=\u001b[49m\u001b[43mline_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\anaconda3\\envs\\riskBorrow\\Lib\\site-packages\\pandas\\io\\formats\\format.py:962\u001b[39m, in \u001b[36mDataFrameRenderer.to_string\u001b[39m\u001b[34m(self, buf, encoding, line_width)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstring\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringFormatter\n\u001b[32m    961\u001b[39m string_formatter = StringFormatter(\u001b[38;5;28mself\u001b[39m.fmt, line_width=line_width)\n\u001b[32m--> \u001b[39m\u001b[32m962\u001b[39m string = \u001b[43mstring_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m save_to_buffer(string, buf=buf, encoding=encoding)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\anaconda3\\envs\\riskBorrow\\Lib\\site-packages\\pandas\\io\\formats\\string.py:29\u001b[39m, in \u001b[36mStringFormatter.to_string\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_string\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     text = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_string_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fmt.should_show_dimensions:\n\u001b[32m     31\u001b[39m         text = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.fmt.dimensions_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\anaconda3\\envs\\riskBorrow\\Lib\\site-packages\\pandas\\io\\formats\\string.py:48\u001b[39m, in \u001b[36mStringFormatter._get_string_representation\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     44\u001b[39m strcols = \u001b[38;5;28mself\u001b[39m._get_strcols()\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.line_width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# no need to wrap around just print the whole frame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madj\u001b[49m\u001b[43m.\u001b[49m\u001b[43madjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstrcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._need_to_wrap_around:\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._join_multiline(strcols)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\anaconda3\\envs\\riskBorrow\\Lib\\site-packages\\pandas\\io\\formats\\printing.py:525\u001b[39m, in \u001b[36m_TextAdjustment.adjoin\u001b[39m\u001b[34m(self, space, *lists, **kwargs)\u001b[39m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madjoin\u001b[39m(\u001b[38;5;28mself\u001b[39m, space: \u001b[38;5;28mint\u001b[39m, *lists, **kwargs) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43madjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mlists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrlen\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjustfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjustify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\anaconda3\\envs\\riskBorrow\\Lib\\site-packages\\pandas\\io\\formats\\printing.py:56\u001b[39m, in \u001b[36madjoin\u001b[39m\u001b[34m(space, *lists, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m maxLen = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlen\u001b[39m, lists))\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, lst \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lists):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     nl = \u001b[43mjustfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     nl = ([\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m * lengths[i]] * (maxLen - \u001b[38;5;28mlen\u001b[39m(lst))) + nl\n\u001b[32m     58\u001b[39m     newLists.append(nl)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\anaconda3\\envs\\riskBorrow\\Lib\\site-packages\\pandas\\io\\formats\\printing.py:518\u001b[39m, in \u001b[36m_TextAdjustment.justify\u001b[39m\u001b[34m(self, texts, max_len, mode)\u001b[39m\n\u001b[32m    514\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    515\u001b[39m \u001b[33;03mPerform ljust, center, rjust against string or list-like\u001b[39;00m\n\u001b[32m    516\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [x.ljust(max_len) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mcenter\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [x.center(max_len) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "\u001b[31mMemoryError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_preprocessing import preprocess_data\n",
    "\n",
    "loan_data = \"data/accepted_2007_to_2018Q4.csv.gz\"\n",
    "unemployment_rate_data = [\"data/unemployment_rate_0.csv\", \"data/unemployment_rate_1.csv\", \"data/unemployment_rate_2.csv\", \"data/unemployment_rate_3.csv\", \"data/unemployment_rate_4.csv\"]\n",
    "\n",
    "data = preprocess_data(loan_data, unemployment_rate_data)\n",
    "print(f'Initial data shape: {data.shape}')\n",
    "print(data.to_string())\n",
    "\n",
    "# Drop non-numeric columns and the target column `default` from features (but keep for reference)\n",
    "if 'default' in data.columns:\n",
    "    y = data['default']\n",
    "else:\n",
    "    y = None\n",
    "numeric_columns = data.columns[data.dtypes.apply(lambda x: np.issubdtype(x, np.number))]\n",
    "\n",
    "# ISSUES WITH MEMORY USAGE\n",
    "data = data[numeric_columns] \n",
    "# non_numeric = [c for c in data.columns if c not in numeric_columns]\n",
    "# data.drop(columns=non_numeric, inplace=True)\n",
    "\n",
    "# Remove IDs\n",
    "for col in ['id','member_id']:\n",
    "    if col in data.columns:\n",
    "        data = data.drop(columns=[col])\n",
    "# Ensure target not included in features\n",
    "if 'default' in data.columns:\n",
    "    data = data.drop(columns=['default'])\n",
    "\n",
    "print(f'Numeric feature count: {data.shape[1]}')\n",
    "\n",
    "# Impute missing values with median\n",
    "imp = SimpleImputer(strategy='median')\n",
    "X_imp = imp.fit_transform(data)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "# Run PCA\n",
    "batch_size = 50000\n",
    "for i in range(0, X_imp.shape[0], batch_size):\n",
    "    scaler.partial_fit(X_imp[i:i+batch_size])\n",
    "\n",
    "# Transform in batches\n",
    "X_scaled = np.zeros_like(X_imp, dtype=np.float32)  # Saves memory vs float64\n",
    "for i in range(0, X_imp.shape[0], batch_size):\n",
    "    X_scaled[i:i+batch_size] = scaler.transform(X_imp[i:i+batch_size])\n",
    "\n",
    "n_components = min(50, X_scaled.shape[1])  # Choose desired number of components (50 is typical)\n",
    "ipca = IncrementalPCA(n_components=n_components)\n",
    "\n",
    "# Fit in chunks\n",
    "for i in range(0, X_scaled.shape[0], batch_size):\n",
    "    ipca.partial_fit(X_scaled[i:i+batch_size])\n",
    "\n",
    "# Transform in chunks\n",
    "X_pca_list = []\n",
    "for i in range(0, X_scaled.shape[0], batch_size):\n",
    "    X_pca_list.append(ipca.transform(X_scaled[i:i+batch_size]))\n",
    "\n",
    "X_pca = np.vstack(X_pca_list)\n",
    "\n",
    "# Explained variance\n",
    "explained = ipca.explained_variance_ratio_\n",
    "cum_explained = np.cumsum(explained)\n",
    "print('10 Explained variance ratio ')\n",
    "print(explained[:10])\n",
    "print('10 Cum variance')\n",
    "print(cum_explained[:10])\n",
    "\n",
    "# Loadings DataFrame (features x components)\n",
    "loadings = pd.DataFrame(ipca.components_.T, index=data.columns, columns=[f'PC{i+1}' for i in range(ipca.n_components_)])\n",
    "importance = (loadings.abs() * explained).sum(axis=1)\n",
    "importance = importance.sort_values(ascending=False)\n",
    "impl_df = pd.DataFrame({'feature': importance.index, 'importance': importance.values})\n",
    "impl_df.to_csv('pca_feature_importance.csv', index=False)\n",
    "\n",
    "#print('Top 20 features by PCA importance:')\n",
    "# print(impl_df.head(20))\n",
    "print('Print all features by PCA importance to -> pca_feature_importance.csv:')\n",
    "\n",
    "top_feats = impl_df['feature'].head(10).tolist()\n",
    "print('Loadings for top features (first 5 PCs):')\n",
    "print(loadings.loc[top_feats, loadings.columns[:5]])\n",
    "\n",
    "# Components to reach 95% variance\n",
    "n_95 = np.searchsorted(cum_explained, 0.95) + 1\n",
    "print(f'Number of components to reach 95% variance: {n_95}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc03c76d",
   "metadata": {},
   "source": [
    "### Logistic Regression on 50 features with highest variance (according to PCA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8756bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 50 components for model input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\riskBorrow\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics:\n",
      "{'accuracy': 0.9592886179760868, 'precision': 0.8039651070578906, 'recall': 0.9205712398877332, 'f1': 0.858325957283048, 'roc_auc': 0.9842582346650408}\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    391564\n",
      "           1       0.80      0.92      0.86     60570\n",
      "\n",
      "    accuracy                           0.96    452134\n",
      "   macro avg       0.90      0.94      0.92    452134\n",
      "weighted avg       0.96      0.96      0.96    452134\n",
      "\n",
      "Confusion matrix:\n",
      "[[377968  13596]\n",
      " [  4811  55759]]\n",
      "Saved metrics to pca_logistic_metrics.csv and coefficients to pca_logistic_coefficients.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "desired = 51\n",
    "if 'n_95' in globals() and isinstance(n_95, int) and n_95 > 0:\n",
    "    n_use = min(desired, ipca.n_components_, n_95)\n",
    "else:\n",
    "    n_use = min(desired, ipca.n_components_)\n",
    "\n",
    "print(f'Using {n_use} components for model input')\n",
    "\n",
    "# Build feature matrix from PCA-transformed data X_pca\n",
    "if 'X_pca' not in globals():\n",
    "    X_pca = ipca.transform(X_scaled)\n",
    "X = X_pca[:, :n_use]\n",
    "\n",
    "try:\n",
    "    y = data['default'] \n",
    "except Exception:\n",
    "    # fall back to checking globals for y from earlier cells\n",
    "    if 'y' in globals() and y is not None:\n",
    "        pass\n",
    "    else:\n",
    "        raise RuntimeError('Target vector `y` not found in notebook namespace. Ensure you saved the original target before overwriting `data`.')\n",
    "\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# Fit logistic regression with balanced class weights\n",
    "clf = LogisticRegression(max_iter=1000, class_weight='balanced', solver='saga')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1] if hasattr(clf, 'predict_proba') else None\n",
    "\n",
    "\n",
    "# Metrics\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "    'f1': f1_score(y_test, y_pred, zero_division=0),\n",
    "}\n",
    "\n",
    "if y_proba is not None:\n",
    "    metrics['roc_auc'] = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print('Evaluation metrics:')\n",
    "print(metrics)\n",
    "\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save metrics and model coefficients\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_df.to_csv('pca_logistic_metrics.csv', index=False)\n",
    "coef_df = pd.DataFrame({'component': [f'PC{i+1}' for i in range(n_use)], 'coef': clf.coef_.ravel()[:n_use]})\n",
    "coef_df.to_csv('pca_logistic_coefficients.csv', index=False)\n",
    "print('Saved metrics to pca_logistic_metrics.csv and coefficients to pca_logistic_coefficients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72577c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan data loaded successfully.\n",
      "Unemployment rate data loaded and merged successfully.\n",
      "Loan and unemployment data merged successfully.\n",
      "Data preprocessing completed successfully.\n",
      "\n",
      "Top 20 Features by Point-Biserial Correlation:\n",
      "                    feature  abs_pointbiserial_corr\n",
      "35     last_fico_range_high                0.609548\n",
      "36      last_fico_range_low                0.556323\n",
      "32               recoveries                0.488174\n",
      "33  collection_recovery_fee                0.463735\n",
      "94     debt_settlement_flag                0.314878\n",
      "7                 sub_grade                0.233739\n",
      "29          total_rec_prncp                0.233454\n",
      "6                     grade                0.229600\n",
      "4                  int_rate                0.211744\n",
      "34          last_pymnt_amnt                0.192632\n",
      "25                out_prncp                0.157300\n",
      "26            out_prncp_inv                0.157285\n",
      "27              total_pymnt                0.145531\n",
      "28          total_pymnt_inv                0.145372\n",
      "31       total_rec_late_fee                0.144559\n",
      "17           fico_range_low                0.122063\n",
      "18          fico_range_high                0.122062\n",
      "95               issue_year                0.112514\n",
      "11      verification_status                0.095424\n",
      "57     acc_open_past_24mths                0.094126\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riskBorrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
